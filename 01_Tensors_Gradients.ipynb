{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "* Tensores são uma matriz de um número, vetores, matrizes ou matrizes n-dimensionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado: 4.0\n",
      "Tipo de dado: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Números\n",
    "print(f\"Dado: {torch.tensor(4.)}\")\n",
    "print(f\"Tipo de dado: {torch.tensor(4.).dtype}\")\n",
    "# 4. é uma abreviação para 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado: tensor([1., 2., 3., 4.])\n",
      "Tipo de dado: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Vetores\n",
    "print(f\"Dado: {torch.tensor([1., 2, 3, 4])}\")\n",
    "print(f\"Tipo de dado: {torch.tensor([1., 2, 3, 4]).dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado: tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]])\n",
      "Tipo de dado: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Matriz\n",
    "print(f\"Dado: {torch.tensor([[1., 2, 3, 4], [5, 6, 7, 8]])}\")\n",
    "print(f\"Tipo de dado: {torch.tensor([[1., 2, 3, 4], [5, 6, 7, 8]]).dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado: tensor([[[ 1.,  2.,  3.,  4.],\n",
      "         [ 5.,  6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11., 12.],\n",
      "         [13., 14., 15., 16.]]])\n",
      "Tipo de dado: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Matriz 3-Dimensional\n",
    "print(\n",
    "    f\"Dado: {torch.tensor([[[1., 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Tipo de dado: {torch.tensor([[[1., 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]]).dtype}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensores podem ter qualquer tanto de dimensões e diferentes comprimentos. Podemos inspecionar o comprimento de cada dimensão utilizando a propriedade `.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão do dado: torch.Size([])\n",
      "Dimensão do dado: torch.Size([4])\n",
      "Dimensão do dado: torch.Size([2, 4])\n",
      "Dimensão do dado: torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor(4.0)  # Escalar\n",
    "t2 = torch.tensor([1.0, 2, 3, 4])  # 1-Dimensional\n",
    "t3 = torch.tensor([[1.0, 2, 3, 4], [5, 6, 7, 8]])  # 2-Dimensional\n",
    "t4 = torch.tensor(\n",
    "    [[[1.0, 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]]\n",
    ")  # 3-Dimensional\n",
    "\n",
    "print(f\"Dimensão do dado: {t1.shape}\")\n",
    "print(f\"Dimensão do dado: {t2.shape}\")\n",
    "print(f\"Dimensão do dado: {t3.shape}\")\n",
    "print(f\"Dimensão do dado: {t4.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações e Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos combinar tensores com algoritmos comuns de operação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de tensores\n",
    "x = torch.tensor(3.0)\n",
    "w = torch.tensor(4.0, requires_grad=True)\n",
    "b = torch.tensor(5.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aritmética\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O que torna o PyTorch unico é que pode calcular automaticamente as derivadas de `y` para os tensores que possuem gradiente requerido. Essa característica se chama Autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula as derivadas\n",
    "y.backward()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx = None\n",
      "dy/dw = 3.0\n",
      "dy/db = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Exibe os gradientes\n",
    "print(f\"dy/dx = {x.grad}\")\n",
    "print(f\"dy/dw = {w.grad}\")\n",
    "print(f\"dy/db = {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradiente e derivada são termos que representam a mesma coisa. O termo \"gradiente\" é mais comumente utilizado no contexto de matrizes e vetores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Além das operações aritméticas, o PyTorch também contém muitas funções para criação e manipulação de tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[42, 42],\n",
       "         [42, 42],\n",
       "         [42, 42]]),\n",
       " tensor([[55., 55.],\n",
       "         [55., 55.],\n",
       "         [55., 55.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando tensores com um valor fixo para todos os elementos\n",
    "t1 = torch.full((3, 2), 42)\n",
    "t2 = torch.full((3, 2), 55.0)\n",
    "t1, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42., 42.],\n",
       "        [42., 42.],\n",
       "        [42., 42.],\n",
       "        [55., 55.],\n",
       "        [55., 55.],\n",
       "        [55., 55.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenando tensores com tamanhos compatíveis\n",
    "t_c = torch.cat((t1, t2))\n",
    "t_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4000, -0.4000],\n",
      "        [-0.4000, -0.4000],\n",
      "        [-0.4000, -0.4000],\n",
      "        [ 0.0221,  0.0221],\n",
      "        [ 0.0221,  0.0221],\n",
      "        [ 0.0221,  0.0221]])\n"
     ]
    }
   ],
   "source": [
    "# Calculando o cosseno de cada elemento\n",
    "print(t_c.cos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[42., 42., 42., 42.],\n",
      "        [42., 42., 55., 55.],\n",
      "        [55., 55., 55., 55.]])\n"
     ]
    }
   ],
   "source": [
    "# Mudando a dimensão de um tensor\n",
    "print(t_c.reshape(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperabilidade com NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4.0]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n",
      "\n",
      "Tipo antigo: float64. Tipo novo: torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Convertendo um array numpy para um tensor\n",
    "y = torch.from_numpy(x)\n",
    "print(y)\n",
    "\n",
    "print(f\"\\nTipo antigo: {x.dtype}. Tipo novo: {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "Tipo antigo: torch.float64. Tipo novo: float64\n"
     ]
    }
   ],
   "source": [
    "# Convertendo um tensor para um array numpy\n",
    "z = y.numpy()\n",
    "print(z)\n",
    "\n",
    "print(f\"\\nTipo antigo: {y.dtype}. Tipo novo: {z.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A interoperabilidade entre PyTorch e Numpy é essencial por conta da maioria dos conjuntos de dados são lidos e processados com numpy.\n",
    "\n",
    "Poderíamos usar apenas o Numpy para o trabalho com dados numéricos multi-dimensionais, mas há alguns pontos:\n",
    "\n",
    "\n",
    "1. Autograd: Conseguir computar automaticamente os gradientes é essencial para o treinamento de modelos de Deep Learning\n",
    "\n",
    "2. GPU's: Trabalhar com conjuntos de dados grandes o bastante para se justificar o uso de redes neurais também requer hardwares específicos para o processamento em paralelo. Podemos realizar o mesmo trabalho que CPU's em minutos, em vez de horas, utilizando GPU's"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
